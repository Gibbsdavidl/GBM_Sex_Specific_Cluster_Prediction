---
title: "STEP_4_5_AIM_1_JIVE_validation.Rmd"
output: html_document
date: "2023-10-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(tidyverse)
library(robencla)
library(survival)
library(survminer)
library(pheatmap)

```

## JIVE Validation

```{r}


# Take the data set, and filter out pair genes that are not present.

clean_genepairs_list <- function(genepairs, dat_x) {
  genepairs_clean <- list()
  i <- 1
  for (pi in names(genepairs)) {
    genes <- genepairs[[pi]]
    missing_genes <- unique( genes [! genes %in% colnames(dat_x)] )
    print(paste0(pi, '  ', missing_genes))
    newpairlist <- c()
    for (j in seq.int(from=1,to=length(genes), by=2)) {
      if ( (genes[j] %in% missing_genes) | (genes[j+1] %in% missing_genes) ) {
        # then don't add them!
        print(paste0("removing from pair list:  ", genes[j], ' ', genes[j+1]))
      } else {
        newpairlist <- c(newpairlist, genes[j], genes[j+1])
      }
    }
    genepairs_clean[[pi]] <- newpairlist
  }
  return(genepairs_clean)
}

# pairlist is a list of vectors (paired terms)
# n is the number of pairs for each entry desired

shorter_and_clean <- function(pairlist, n) {
  newlist <- list()
  for (ni in names(pairlist)) {
    newlist[[ni]] <- str_replace_all(pairlist[[ni]][1:(2*n)], '\\.', '_')
  }
  return(newlist)  
}


save_pheatmap_pdf <- function(x, filename, width=7, height=7) {
    stopifnot(!missing(x))
    stopifnot(!missing(filename))
    pdf(filename, width=width, height=height)
    grid::grid.newpage()
    grid::grid.draw(x$gtable)
    dev.off()
}


```


```{r}
load('../data/F_processed_data.rda')
load('../results/genepair_features/females_genepairs.rda')


# missign in val
# Show in New Window
# [1] "cluster1  "
# [1] "cluster2  RPS25"
# [1] "removing from pair list:  RPS25 VEGFA"
# [1] "cluster3  FABP5" "cluster3  CD24" 
# [1] "removing from pair list:  C1QL1 FABP5"
# [1] "removing from pair list:  CD24 LGALS3"
# [1] "cluster4  "
# [1] "cluster5  GOLGA8N" "cluster5  METTL7A"
# [1] "removing from pair list:  PLPPR1 GOLGA8N"
# [1] "removing from pair list:  FABP7 METTL7A"
```


First training the full model with all data.


```{r}
gpairs <- shorter_and_clean(genepairs, 12)  # gset4 here too.
genepairs_cl <- clean_genepairs_list(genepairs, dat_f)  # only one with missing genes
genepairs_cl <- clean_genepairs_list(genepairs_cl, val_f)  # only one with missing genes


# xgboost parameters to pass to each sub-classifier in the ensembles
params1 <- list(
               max_depth=12,   # "height" of the tree, 6 is actually default. (xgboost parameter)
               eta=0.45,        # this is the learning rate. smaller values slow it down,   (xgboost parameter)
               nrounds=24,     # number of rounds of training, lower numbers less overfitting (xgboost parameter)
               early_stopping_rounds=2,
               nthreads=8,     # parallel threads
               gamma=0.2,      # Minimum loss req'd to again partition a leaf node. higher ~ conservative (xgboost)
               lambda=2.5,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
               alpha=0.25,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
               verbose=0,
               train_perc=0.8,
               combine_function='median',
               size=11
)


mod_f <- robencla::Robencla$new('f_model')


mod_f$train(data_frame=dat_f,
            label_name='ClusterLabel', #'ClusterLabel2',
            sample_id = 'Barcode',
            drop_list = c(),
            data_mode=c('pairs'),    # pairs, allpairs, sigpairs, quartiles, tertiles, binarize, ranks, original #
            signatures=NULL,         # 
            pair_list=genepairs_cl,  # c3_pairs   # subset to these genes.
            params=params1
            )


# run the model
mod_f$predict(data_frame = val_f, 
              sample_id = 'Barcode',
              drop_list = c())


table(mod_f$results()$BestCall)
# cluster1 cluster2 cluster3 cluster4 cluster5 
#       69       17       94       29       95 


# get the results table
resdf <- mod_f$results()
# add in the survival and censored
resdf$Survival <- mod_f$test_data$Survival
resdf$Censored <- mod_f$test_data$Censored

# convert scores to numerics
resdf$cluster1 <- unlist(resdf$cluster1)
resdf$cluster2 <- unlist(resdf$cluster2)
resdf$cluster3 <- unlist(resdf$cluster3)
resdf$cluster4 <- unlist(resdf$cluster4)
resdf$cluster5 <- unlist(resdf$cluster5)

resdf$CensoredCode <- ifelse(resdf$Censored == 0, yes=1, no=2)

modfit <- survfit(Surv(Survival, CensoredCode)~BestCalls,data=resdf)
ggsurvplot(modfit, pval = T, xlim=c(0,1700))
ggsave('../figures/females_validation_survival_curve.pdf', width = 8, height = 8)
#ggsave('../figures/females_validation_survival_curve_curated_genepairs.pdf', width = 8, height = 8)



val_dat <- as.data.frame(mod_f$test_data)
val_dat$ClusterLabel <- resdf$BestCalls


imp_list <- mod_f$importance()
df1 <- data.frame(Top10=1:10, Cluster='cluster1',imp_list[['cluster1']][1:10,])
df2 <- data.frame(Top10=1:10, Cluster='cluster2',imp_list[['cluster2']][1:10,])
df3 <- data.frame(Top10=1:10, Cluster='cluster3',imp_list[['cluster3']][1:10,])
df4 <- data.frame(Top10=1:10, Cluster='cluster4',imp_list[['cluster4']][1:10,])
df5 <- data.frame(Top10=1:10, Cluster='cluster5',imp_list[['cluster5']][1:10,])
impdf <- rbind(df1,df2,df3,df4,df5)

write.csv(impdf, file='../results/TCGA_F_feature_importance.csv')

```

```{r}

save(mod_f, file='../results/models/F_VAL_array.rda')

write.csv(resdf, file='../results/females_validation_results_table.csv')

save(val_dat, file='../results/val_array_data_with_labels.rda')

```



test the validation array annotations for accuracy!

```{r}

# test the validation array annotations for accuracy!

# xgboost parameters to pass to each sub-classifier in the ensembles
# xgboost parameters to pass to each sub-classifier in the ensembles
params1 <- list(max_depth=12,   # "height" of the tree, 6 is actually default.   (xgboost parameter)
               eta=0.45,        # this is the learning rate. smaller values , more  conservative   (xgboost parameter)
               nrounds=24,     # number of rounds of training, lower numbers less overfitting  (xgboost parameter)
               early_stopping_rounds=2,
               nthreads=8,     # parallel threads
               gamma=0.2,      # Minimum loss req'd to again partition a leaf node. higher~ conservative (xgboost)
               lambda=2.5,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
               alpha=0.25,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
               verbose=0,
               train_perc=0.8,
               combine_function='median',
               size=11
)


mod_f <- robencla::Robencla$new('f_model')


mod_f$train(data_frame=val_dat,
            label_name='ClusterLabel', #'ClusterLabel2',
            sample_id = 'SampleID',
            drop_list = c(),
            data_mode=c('pairs'),    # pairs, allpairs, sigpairs, quartiles, tertiles, binarize, ranks, original #
            signatures=NULL,         # 
            pair_list=genepairs_cl,  # c3_pairs   # subset to these genes.
            params=params1
            )


# run the model
mod_f$predict(data_frame = dat_f, 
              sample_id  = 'Barcode',
              label_name = 'ClusterLabel')


## check results
tabdf <- table(Pred=mod_f$results()$BestCall, True=mod_f$test_label)
print(tabdf)


# make the heatmap
tabtbl <- as.data.frame(tabdf) %>% 
  pivot_wider(id_cols = Pred, names_from = True, values_from = Freq) %>% 
  select(-Pred) #%>%
  #scale(center = F) # Z-scores
rownames(tabtbl) <- colnames(tabtbl)

p <- pheatmap(tabtbl, cluster_rows = F, cluster_cols = F, display_numbers = T, 
              scale = 'column', fontsize_number = 12)


metrics <- mod_f$classification_metrics(these_labels = mod_f$test_label, these_calls = mod_f$results()$BestCall,use_cv_results = F)

metrics

write_csv(metrics, file='../results/females_ValPred_to_TCGA_metrics_step4_5.csv')

save_pheatmap_pdf(p, "../figures/females_ValPred_to_TCGA_heatmap_step_4_5.pdf", width=5, height=5)

save(mod_f, file='../results/models/F_ValPred_to_TCGA_step4_5.rda')          


  #          cluster1 cluster2 cluster3 cluster4 cluster5
  # cluster1       39        1        0        2        2
  # cluster2        1       18        0        1        0
  # cluster3        0        0       13        0        0
  # cluster4        0        0        0       15        0
  # cluster5        1        5        1        2       38

```











First training the full model with all male data.
```{r}

# see data set up
load('../data/M_processed_data.rda')
load('../results/males_genepairs.rda')

```


```{r}

gpairs <- shorter_and_clean(genepairs, 12)
genepairs_cl <- clean_genepairs_list(gpairs, dat_m)  # only one with missing genes
genepairs_cl <- clean_genepairs_list(genepairs_cl, val_m)  # only one with missing genes

# xgboost parameters to pass to each sub-classifier in the ensembles
params1 <- list(max_depth=12,   # "height" of the tree, 6 is actually default.   (xgboost parameter)
               eta=0.45,        # this is the learning rate. smaller values , more  conservative   (xgboost parameter)
               nrounds=24,     # number of rounds of training, lower numbers less overfitting  (xgboost parameter)
               early_stopping_rounds=2,
               nthreads=8,     # parallel threads
               gamma=0.2,      # Minimum loss req'd to again partition a leaf node. higher~ conservative (xgboost)
               lambda=2.5,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
               alpha=0.25,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
               verbose=0,
               train_perc=0.8,
               combine_function='median',
               size=11
)

mod_m <- robencla::Robencla$new('m_model')

mod_m$train(data_frame=dat_m,
            label_name='ClusterLabel', #'ClusterLabel',
            sample_id = 'Barcode',
            drop_list = c(),
            data_mode=c('pairs'),    # pairs, allpairs, sigpairs, quartiles, tertiles, binarize, ranks, original #
            signatures=NULL,         # 
            pair_list=genepairs_cl, #genepairs_cl, # c3_pairs  # subset to these genes.
            params=params1
            )


# run the model
mod_m$predict(data_frame = val_m,
              sample_id = 'Barcode')



table(mod_m$results()$BestCall)
#cluster1 cluster2 cluster3 cluster5 
#      18      199       83      236 
      
# get the results table
resdf <- mod_m$results()
# add in the survival and censored
resdf$Survival <- mod_m$test_data$Survival
resdf$Censored <- mod_m$test_data$Censored

# convert scores to numerics
resdf$cluster1 <- unlist(resdf$cluster1)
resdf$cluster2 <- unlist(resdf$cluster2)
resdf$cluster3 <- unlist(resdf$cluster3)
resdf$cluster4 <- unlist(resdf$cluster4)
resdf$cluster5 <- unlist(resdf$cluster5)

resdf$CensoredCode <- ifelse(resdf$Censored == 0, yes=1, no=2)

modfit <- survfit(Surv(Survival, CensoredCode)~BestCalls,data=resdf)
ggsurvplot(modfit, pval = T, xlim=c(0,1700))

ggsave('../figures/females_validation_survival_curve.pdf')


ggsave('../figures/males_validation_survival_curve_with_females_curated_features.pdf', width = 8, height = 8)


val_dat <- as.data.frame(mod_m$test_data)
val_dat$ClusterLabel <- resdf$BestCalls



```

```{r}

save(mod_m, file='../results/models/M_VAL_array.rda')

write.csv(resdf, file='../results/males_validation_results_table.csv')

save(val_dat, file='../results/males_val_array_data_with_labels.rda')

```



test the validation array annotations for accuracy!

```{r}

# test the validation array annotations for accuracy!
# xgboost parameters to pass to each sub-classifier in the ensembles
params1 <- list(max_depth=12,   # "height" of the tree, 6 is actually default.   (xgboost parameter)
               eta=0.45,        # this is the learning rate. smaller values , more  conservative   (xgboost parameter)
               nrounds=24,     # number of rounds of training, lower numbers less overfitting  (xgboost parameter)
               early_stopping_rounds=2,
               nthreads=8,     # parallel threads
               gamma=0.2,      # Minimum loss req'd to again partition a leaf node. higher~ conservative (xgboost)
               lambda=2.5,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
               alpha=0.25,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
               verbose=0,
               train_perc=0.8,
               combine_function='median',
               size=11
)


mod_m2 <- robencla::Robencla$new('m_model')

mod_m2$train(data_frame=val_dat,
            label_name='ClusterLabel', #'ClusterLabel2',
            sample_id = 'Barcode',
            data_mode=c('pairs'),    # pairs, allpairs, sigpairs, quartiles, tertiles, binarize, ranks, original #
            signatures=NULL,         # 
            pair_list=genepairs_cl,  # c3_pairs   # subset to these genes.
            params=params1
            )


# run the model
mod_m2$predict(data_frame = dat_m, 
              sample_id  = 'Barcode',
              label_name = 'ClusterLabel')




## check results
tabdf <- table(Pred=mod_m2$results()$BestCall, True=mod_m2$test_label)
print(tabdf)


# make the heatmap
tabtbl <- as.data.frame(tabdf) %>% 
  pivot_wider(id_cols = Pred, names_from = True, values_from = Freq) %>% 
  select(-Pred) #%>%
  #scale(center = F) # Z-scores
rownames(tabtbl) <- c("cluster1","cluster2","cluster3","cluster5")

p <- pheatmap(tabtbl, cluster_rows = F, cluster_cols = F, display_numbers = T, 
              scale = 'column', fontsize_number = 12)



metrics <- mod_m2$classification_metrics(these_labels = mod_m2$test_label, these_calls = mod_m2$results()$BestCall,use_cv_results = F)

metrics

write_csv(metrics, file='../results/males_ValPred_to_TCGA_metrics_step4_5.csv')

save_pheatmap_pdf(p, "../figures/males_ValPred_to_TCGA_heatmap_step_4_5.pdf", width=5, height=5)

save(mod_m2, file='../results/models/M_ValPred_to_TCGA_step4_5.rda')


#           True
# Pred       cluster1 cluster2 cluster3 cluster4 cluster5
#   cluster1       31        5        1        2        2
#   cluster2        1       71        1        7        1
#   cluster3        1        2       27        6        0
#   cluster5        5        7        6       11       33

	
# cluster1	cluster1	0.7363636	0.8157895	0.9450549	0.7560976	0.7848101
# cluster2	cluster2	0.7363636	0.8352941	0.9259259	0.8765432	0.8554217
# cluster3	cluster3	0.7363636	0.7714286	0.9513514	0.7500000	0.7605634
# cluster4	cluster4	0.7363636	0.0000000	1.0000000	0.0000000	0.0000000
# cluster5	cluster5	0.7363636	0.9166667	0.8423913	0.5322581	0.6734694
# Average	Average	0.7363636	0.6678358	0.9329447	0.5829798	0.6148529

```









